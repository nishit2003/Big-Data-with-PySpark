{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bf358d9-e981-4e50-875a-9f9c2ca91727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nishit Grover - M15329773"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cdc3e382-06fa-4000-a6ef-aa6c87877e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /opt/anaconda3/lib/python3.12/site-packages (3.5.3)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/anaconda3/lib/python3.12/site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cfd95b79-3bb4-47d4-904e-b32eb3b9ea60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: ./weather_data/2015_72429793812.csv\n",
      "Successfully downloaded: ./weather_data/2015_99495199999.csv\n",
      "Successfully downloaded: ./weather_data/2016_72429793812.csv\n",
      "File not found on server for Year: 2016, Station: 99495199999\n",
      "Successfully downloaded: ./weather_data/2017_72429793812.csv\n",
      "Successfully downloaded: ./weather_data/2017_99495199999.csv\n",
      "Successfully downloaded: ./weather_data/2018_72429793812.csv\n",
      "Successfully downloaded: ./weather_data/2018_99495199999.csv\n",
      "Successfully downloaded: ./weather_data/2019_72429793812.csv\n",
      "Successfully downloaded: ./weather_data/2019_99495199999.csv\n",
      "Successfully downloaded: ./weather_data/2020_72429793812.csv\n",
      "Successfully downloaded: ./weather_data/2020_99495199999.csv\n",
      "Successfully downloaded: ./weather_data/2021_72429793812.csv\n",
      "Successfully downloaded: ./weather_data/2021_99495199999.csv\n",
      "Successfully downloaded: ./weather_data/2022_72429793812.csv\n",
      "Successfully downloaded: ./weather_data/2022_99495199999.csv\n",
      "Successfully downloaded: ./weather_data/2023_72429793812.csv\n",
      "Successfully downloaded: ./weather_data/2023_99495199999.csv\n",
      "Successfully downloaded: ./weather_data/2024_72429793812.csv\n",
      "Successfully downloaded: ./weather_data/2024_99495199999.csv\n",
      "\n",
      "Summary of Rows Processed per Station:\n",
      "\n",
      "Cincinnati (Station: 72429793812)\n",
      "  Year: 2015 --> Rows Processed: 365\n",
      "  Year: 2016 --> Rows Processed: 366\n",
      "  Year: 2017 --> Rows Processed: 365\n",
      "  Year: 2018 --> Rows Processed: 365\n",
      "  Year: 2019 --> Rows Processed: 365\n",
      "  Year: 2020 --> Rows Processed: 366\n",
      "  Year: 2021 --> Rows Processed: 365\n",
      "  Year: 2022 --> Rows Processed: 365\n",
      "  Year: 2023 --> Rows Processed: 365\n",
      "  Year: 2024 --> Rows Processed: 301\n",
      "  Total Rows Processed for Cincinnati: 3588\n",
      "\n",
      "Florida (Station: 99495199999)\n",
      "  Year: 2015 --> Rows Processed: 355\n",
      "  Year: 2017 --> Rows Processed: 283\n",
      "  Year: 2018 --> Rows Processed: 363\n",
      "  Year: 2019 --> Rows Processed: 345\n",
      "  Year: 2020 --> Rows Processed: 365\n",
      "  Year: 2021 --> Rows Processed: 104\n",
      "  Year: 2022 --> Rows Processed: 259\n",
      "  Year: 2023 --> Rows Processed: 276\n",
      "  Year: 2024 --> Rows Processed: 133\n",
      "  Total Rows Processed for Florida: 2483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Base URL for NOAA data and directory for local data storage\n",
    "BASE_URL = \"https://www.ncei.noaa.gov/data/global-summary-of-the-day/access\"\n",
    "DATA_DIRECTORY = \"./weather_data\"\n",
    "\n",
    "# Create the data directory if it doesn't exist\n",
    "os.makedirs(DATA_DIRECTORY, exist_ok=True)\n",
    "\n",
    "# Year range and station identifiers\n",
    "years = range(2015, 2025)  # Last year is exclusive\n",
    "stations = [\"72429793812\", \"99495199999\"]\n",
    "\n",
    "# Function to download file with error handling\n",
    "def download_file(url, local_filename):\n",
    "    try:\n",
    "        with requests.get(url, stream=True) as response:\n",
    "            response.raise_for_status()\n",
    "            with open(local_filename, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "            print(f\"Successfully downloaded: {local_filename}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error! Failed to download {url}: {e}\")\n",
    "\n",
    "# Loop over years and stations to download data\n",
    "for year in YEARS:\n",
    "    year_url = f\"{BASE_URL}/{year}/\"\n",
    "    try:\n",
    "        response = requests.get(year_url)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException:\n",
    "        print(f\"Error! Failed to access: {year_url}\")\n",
    "        continue\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    links = {link.get('href') for link in soup.find_all('a')}\n",
    "\n",
    "    for station in stations:\n",
    "        filename = f\"{station}.csv\"\n",
    "        if filename in links:\n",
    "            file_url = f\"{year_url}{filename}\"\n",
    "            local_path = os.path.join(DATA_DIRECTORY, f\"{year}_{filename}\")\n",
    "            download_file(file_url, local_path)\n",
    "        else:\n",
    "            print(f\"File not found on server for Year: {year}, Station: {station}\")\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Weather Data Analysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Analyze data and count rows per file\n",
    "# Calculate the total rows processed across all stations and years\n",
    "total_rows_processed = sum(count for _, _, count in dataset_counts)\n",
    "\n",
    "# Detailed summary per station\n",
    "print(\"\\nSummary of Rows Processed per Station:\\n\")\n",
    "\n",
    "for station in stations:\n",
    "    location = \"Cincinnati\" if station == \"72429793812\" else \"Florida\"\n",
    "    print(f\"{location} (Station: {station})\")\n",
    "    yearly_counts = [(year, count) for year, st, count in dataset_counts if st == station]\n",
    "    \n",
    "    for year, count in yearly_counts:\n",
    "        print(f\"  Year: {year} --> Rows Processed: {count}\")\n",
    "    \n",
    "    # Total rows for each station\n",
    "    station_total = sum(count for _, st, count in dataset_counts if st == station)\n",
    "    print(f\"  Total Rows Processed for {location}: {station_total}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f95f50f9-de16-4222-8452-6bc05a8573bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hottest Days by Year (Cincinnati and Florida):\n",
      "\n",
      " Year  |    Station   |                 Station Name                       |    Date      | Maximum Temperature\n",
      "-------|--------------|----------------------------------------------------|--------------|---------------------\n",
      " 2015  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   |  2015-06-12  |                 91.9\n",
      " 2015  | 99495199999  | SEBASTIAN INLET STATE PARK, FL US                  |  2015-07-28  |                 90.0\n",
      "\n",
      "\n",
      " 2016  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   |  2016-07-24  |                 93.9\n",
      "\n",
      "\n",
      " 2017  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   |  2017-07-22  |                 91.9\n",
      " 2017  | 99495199999  | SEBASTIAN INLET STATE PARK, FL US                  |  2017-05-13  |                 88.3\n",
      "\n",
      "\n",
      " 2018  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   |  2018-07-04  |                 96.1\n",
      " 2018  | 99495199999  | SEBASTIAN INLET STATE PARK, FL US                  |  2018-09-15  |                 90.1\n",
      "\n",
      "\n",
      " 2019  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   |  2019-09-30  |                 95.0\n",
      " 2019  | 99495199999  | SEBASTIAN INLET STATE PARK, FL US                  |  2019-09-06  |                 91.6\n",
      "\n",
      "\n",
      " 2020  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   |  2020-07-05  |                 93.9\n",
      " 2020  | 99495199999  | SEBASTIAN INLET STATE PARK, FL US                  |  2020-04-13  |                 91.8\n",
      "\n",
      "\n",
      " 2021  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   |  2021-08-12  |                 95.0\n",
      " 2021  | 99495199999  | SEBASTIAN INLET STATE PARK, FL US                  |  2021-04-18  |                 86.2\n",
      "\n",
      "\n",
      " 2022  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   |  2022-06-14  |                 96.1\n",
      " 2022  | 99495199999  | SEBASTIAN INLET STATE PARK, FL US                  |  2022-05-06  |                 89.6\n",
      "\n",
      "\n",
      " 2023  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   |  2023-08-23  |                 96.1\n",
      " 2023  | 99495199999  | SEBASTIAN INLET STATE PARK, FL US                  |  2023-07-09  |                 90.9\n",
      "\n",
      "\n",
      " 2024  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   |  2024-08-30  |                100.9\n",
      " 2024  | 99495199999  | SEBASTIAN INLET STATE PARK, FL US                  |  2024-05-14  |                 86.7\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col, max as spark_max, lit\n",
    "\n",
    "hottest_days = []\n",
    "\n",
    "# Loop through years and stations to find the hottest day for each year\n",
    "for year in years:\n",
    "    for station in stations:\n",
    "        file_path = f\"{data_directory}/{year}_{station}.csv\"\n",
    "        if os.path.exists(file_path):\n",
    "            df = spark.read.option(\"header\", \"true\").csv(file_path)\n",
    "            valid_df = df.filter(col(\"MAX\") != 9999.9)\n",
    "            max_temp = valid_df.agg(spark_max(\"MAX\").alias(\"Max_Temp\")).collect()[0][\"Max_Temp\"]\n",
    "\n",
    "            hottest_day = valid_df.filter(col(\"MAX\") == max_temp) \\\n",
    "                                  .select(\"STATION\", \"NAME\", \"DATE\", \"MAX\") \\\n",
    "                                  .withColumn(\"YEAR\", lit(year)) \\\n",
    "                                  .collect()[0]\n",
    "\n",
    "            hottest_days.append(Row(YEAR=year, STATION=hottest_day[\"STATION\"], NAME=hottest_day[\"NAME\"], DATE=hottest_day[\"DATE\"], MAX=hottest_day[\"MAX\"]))\n",
    "\n",
    "hottest_days_df = spark.createDataFrame(hottest_days).orderBy(\"YEAR\")\n",
    "\n",
    "# Display the formatted output\n",
    "grouped_years = hottest_days_df.collect()\n",
    "print(\"Hottest Days by Year (Cincinnati and Florida):\\n\")\n",
    "print(f\" Year  |    Station   |                 Station Name                       |    Date      | Maximum Temperature\")\n",
    "print(f\"-------|--------------|----------------------------------------------------|--------------|---------------------\")\n",
    "\n",
    "last_year = None\n",
    "for row in grouped_years:\n",
    "    if last_year and row['YEAR'] != last_year:\n",
    "        print(\"\\n\")  # Extra line for readability\n",
    "    print(f\"{row['YEAR']:^6} | {row['STATION']:^12} | {row['NAME']:<50} | {row['DATE']:^12} | {float(row['MAX']):>20.1f}\")\n",
    "    last_year = row['YEAR']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d2bb96e3-a642-4aee-9624-e215718e3375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coldest Day in March (2015-2024) across all stations:\n",
      "\n",
      " Year  |    Station   |                 Station Name                       |    Date      | Minimum Temperature\n",
      "-------|--------------|----------------------------------------------------|--------------|---------------------\n",
      " 2015  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   |  2015-03-06  |     3.2\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col, min as spark_min, lit, month\n",
    "\n",
    "# List to store the coldest day in March across all years and stations\n",
    "march_min_temps = []\n",
    "\n",
    "# Loop through years and stations to find the coldest day in March\n",
    "for year in years:\n",
    "    for station in stations:\n",
    "        file_path = f\"{data_directory}/{year}_{station}.csv\"\n",
    "        if os.path.exists(file_path):\n",
    "            df = spark.read.option(\"header\", \"true\").csv(file_path)\n",
    "            # Filter data for the month of March and get the minimum temperature\n",
    "            march_df = df.filter(month(col(\"DATE\")) == 3)\n",
    "            min_temp = march_df.agg(spark_min(\"MIN\").alias(\"Min_Temp\")).collect()[0][\"Min_Temp\"]\n",
    "            \n",
    "            if min_temp is not None:\n",
    "                # Get details of the coldest day in March\n",
    "                coldest_day = march_df.filter(col(\"MIN\") == min_temp) \\\n",
    "                                      .select(\"STATION\", \"NAME\", \"DATE\", \"MIN\") \\\n",
    "                                      .withColumn(\"YEAR\", lit(year)) \\\n",
    "                                      .collect()[0]\n",
    "                march_min_temps.append(Row(YEAR=year, STATION=coldest_day[\"STATION\"], NAME=coldest_day[\"NAME\"], DATE=coldest_day[\"DATE\"], MIN=coldest_day[\"MIN\"]))\n",
    "\n",
    "# Create a DataFrame and find the coldest day across all years\n",
    "march_min_temps_df = spark.createDataFrame(march_min_temps)\n",
    "coldest_march_day = march_min_temps_df.orderBy(\"MIN\").limit(1).collect()[0]\n",
    "\n",
    "# Display the result in a table format\n",
    "print(\"\\nColdest Day in March (2015-2024) across all stations:\\n\")\n",
    "print(f\" Year  |    Station   |                 Station Name                       |    Date      | Minimum Temperature\")\n",
    "print(f\"-------|--------------|----------------------------------------------------|--------------|---------------------\")\n",
    "print(f\"{coldest_march_day['YEAR']:^6} | {coldest_march_day['STATION']:^12} | {coldest_march_day['NAME']:<50} | {coldest_march_day['DATE']:^12} | {float(coldest_march_day['MIN']):>7.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1ed86974-dd77-43a5-b78a-2ece4177a6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Year with Most Precipitation for Cincinnati and Florida:\n",
      "\n",
      " Year  |    Station   |                 Station Name                       | Mean PRCP\n",
      "-------|--------------|----------------------------------------------------|----------\n",
      " 2024  | 72429793812  | CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US   | 5.44\n",
      " 2020  | 99495199999  | SEBASTIAN INLET STATE PARK, FL US                  | 0.00\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "from pyspark.sql.functions import year, col, mean\n",
    "\n",
    "# Load data for Cincinnati and calculate mean precipitation by year\n",
    "cincinnati_files = [f\"{data_directory}/{year}_72429793812.csv\" for year in years]\n",
    "cincinnati_df = spark.read.option(\"header\", \"true\").csv(cincinnati_files)\n",
    "\n",
    "cincinnati_precip = cincinnati_df.withColumn(\"YEAR\", year(col(\"DATE\"))) \\\n",
    "    .groupBy(\"YEAR\", \"STATION\", \"NAME\") \\\n",
    "    .agg(mean(\"PRCP\").alias(\"Mean_PRCP\")) \\\n",
    "    .orderBy(col(\"Mean_PRCP\").desc()) \\\n",
    "    .limit(1)\n",
    "\n",
    "# Load data for Florida (excluding 2016) and calculate mean precipitation by year\n",
    "florida_files = [f\"{data_directory}/{year}_99495199999.csv\" for year in years if year != 2016]\n",
    "florida_df = spark.read.option(\"header\", \"true\").csv(florida_files)\n",
    "\n",
    "florida_precip = florida_df.withColumn(\"YEAR\", year(col(\"DATE\"))) \\\n",
    "    .groupBy(\"YEAR\", \"STATION\", \"NAME\") \\\n",
    "    .agg(mean(\"PRCP\").alias(\"Mean_PRCP\")) \\\n",
    "    .orderBy(col(\"Mean_PRCP\").desc()) \\\n",
    "    .limit(1)\n",
    "\n",
    "# Collect results\n",
    "cincinnati_result = cincinnati_precip.collect()[0]\n",
    "florida_result = florida_precip.collect()[0]\n",
    "\n",
    "# Display results in a table format\n",
    "print(\"\\nYear with Most Precipitation for Cincinnati and Florida:\\n\")\n",
    "print(f\" Year  |    Station   |                 Station Name                       | Mean PRCP\")\n",
    "print(f\"-------|--------------|----------------------------------------------------|----------\")\n",
    "print(f\"{cincinnati_result['YEAR']:^6} | {cincinnati_result['STATION']:^12} | {cincinnati_result['NAME']:<50} | {cincinnati_result['Mean_PRCP']:.2f}\")\n",
    "print(f\"{florida_result['YEAR']:^6} | {florida_result['STATION']:^12} | {florida_result['NAME']:<50} | {florida_result['Mean_PRCP']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "01a07430-ddd8-4afe-b034-23f45b7fec00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentage of Missing Values for Wind Gust (column GUST) in 2024:\n",
      "\n",
      "Cincinnati: 39.53%\n",
      "Florida: 100.00%\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Define file paths for 2024 data\n",
    "cincinnati_2024_file = \"./weather_data/2024_72429793812.csv\"\n",
    "florida_2024_file = \"./weather_data/2024_99495199999.csv\"\n",
    "\n",
    "# Load 2024 data for Cincinnati and Florida\n",
    "cincinnati_2024_df = spark.read.option(\"header\", \"true\").csv(cincinnati_2024_file)\n",
    "florida_2024_df = spark.read.option(\"header\", \"true\").csv(florida_2024_file)\n",
    "\n",
    "# Function to calculate missing percentage for GUST\n",
    "def calculate_missing_percentage(df, location):\n",
    "    missing_count = df.filter(col(\"GUST\") == 999.9).count()\n",
    "    total_count = df.count()\n",
    "    missing_percentage = (missing_count / total_count) * 100\n",
    "    return f\"{location}: {missing_percentage:.2f}%\"\n",
    "\n",
    "# Calculate missing percentages for Cincinnati and Florida\n",
    "cincinnati_missing_percentage = calculate_missing_percentage(cincinnati_2024_df, \"Cincinnati\")\n",
    "florida_missing_percentage = calculate_missing_percentage(florida_2024_df, \"Florida\")\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nPercentage of Missing Values for Wind Gust (column GUST) in 2024:\\n\")\n",
    "print(cincinnati_missing_percentage)\n",
    "print(florida_missing_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "add53151-1a23-4348-a05d-167ce57ddac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Temperature Statistics for Cincinnati for Each Month in 2020:\n",
      "\n",
      "+-----+------------------+-----------+---------+------------------+\n",
      "|MONTH|Mean_TEMP         |Median_TEMP|Mode_TEMP|StdDev_TEMP       |\n",
      "+-----+------------------+-----------+---------+------------------+\n",
      "|1    |37.945161081129505|37.7       |24.7     |8.345810838316384 |\n",
      "|2    |36.58965525133856 |36.0       |25.9     |7.901597947537755 |\n",
      "|3    |49.0741934007214  |47.8       |39.6     |8.77940669347644  |\n",
      "|4    |51.77999992370606 |51.0       |49.4     |7.3131621276074465|\n",
      "|5    |60.89032290058751 |63.7       |73.9     |9.314768319579512 |\n",
      "|6    |72.54666570027669 |73.7       |70.7     |4.8999458590264515|\n",
      "|7    |77.6000001968876  |77.9       |78.4     |2.337947626620972 |\n",
      "|8    |73.34516143798828 |73.7       |78.3     |3.4878690606063563|\n",
      "|9    |66.09999961853028 |65.8       |74.5     |7.118261579669542 |\n",
      "|10   |55.19354851015152 |54.0       |52.2     |6.7286914818367975|\n",
      "|11   |48.00333340962728 |47.7       |47.7     |6.825938707865554 |\n",
      "|12   |35.99354830095845 |35.2       |32.1     |6.6427872766495755|\n",
      "+-----+------------------+-----------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "from pyspark.sql.functions import col, month, mean, stddev, expr, count, when\n",
    "from pyspark.sql import Window\n",
    "\n",
    "# Define file path and load 2020 data for Cincinnati\n",
    "cincinnati_2020_file = \"./weather_data/2020_72429793812.csv\"\n",
    "cincinnati_2020_df = spark.read.option(\"header\", \"true\").csv(cincinnati_2020_file)\n",
    "\n",
    "# Convert TEMP to float and filter out invalid values\n",
    "cincinnati_2020_df = cincinnati_2020_df.withColumn(\"TEMP\", col(\"TEMP\").cast(\"float\")) \\\n",
    "    .filter((col(\"TEMP\") != 9999.9) & col(\"TEMP\").isNotNull()) \\\n",
    "    .withColumn(\"MONTH\", month(col(\"DATE\")))\n",
    "\n",
    "# Calculate mean, standard deviation, and median for each month\n",
    "temp_stats_df = cincinnati_2020_df.groupBy(\"MONTH\") \\\n",
    "    .agg(\n",
    "        mean(\"TEMP\").alias(\"Mean_TEMP\"),\n",
    "        stddev(\"TEMP\").alias(\"StdDev_TEMP\"),\n",
    "        expr(\"percentile_approx(TEMP, 0.5)\").alias(\"Median_TEMP\")\n",
    "    )\n",
    "\n",
    "# Calculate mode for each month\n",
    "mode_df = cincinnati_2020_df.groupBy(\"MONTH\", \"TEMP\") \\\n",
    "    .agg(count(\"TEMP\").alias(\"Frequency\")) \\\n",
    "    .withColumn(\"Max_Frequency\", expr(\"max(Frequency) over (PARTITION BY MONTH)\")) \\\n",
    "    .filter(col(\"Frequency\") == col(\"Max_Frequency\")) \\\n",
    "    .groupBy(\"MONTH\") \\\n",
    "    .agg(expr(\"first(TEMP)\").alias(\"Mode_TEMP\"))\n",
    "\n",
    "# Combine statistics into a single DataFrame\n",
    "final_stats_df = temp_stats_df.join(mode_df, \"MONTH\").orderBy(\"MONTH\")\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nTemperature Statistics for Cincinnati for Each Month in 2020:\\n\")\n",
    "final_stats_df.select(\n",
    "    col(\"MONTH\"),\n",
    "    col(\"Mean_TEMP\"),\n",
    "    col(\"Median_TEMP\"),\n",
    "    col(\"Mode_TEMP\"),\n",
    "    col(\"StdDev_TEMP\")\n",
    ").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f9da14da-5e69-452d-b054-fa4d240ff219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Days with the Lowest Wind Chill for Cincinnati in 2017:\n",
      "\n",
      "+------------------------------------------------+----------+----+----+-------------------+\n",
      "|NAME                                            |DATE      |TEMP|WDSP|Wind_Chill         |\n",
      "+------------------------------------------------+----------+----+----+-------------------+\n",
      "|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2017-01-07|10.5|7.0 |-0.4140156367932173|\n",
      "|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2017-12-31|11.0|5.3 |2.0339764741541018 |\n",
      "|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2017-12-27|13.0|5.8 |3.8206452986638073 |\n",
      "|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2017-12-28|13.6|5.8 |4.533355513517824  |\n",
      "|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2017-01-06|13.6|5.5 |4.868933492954463  |\n",
      "|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2017-01-08|15.9|5.2 |7.929747979856229  |\n",
      "|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2017-12-25|25.8|13.5|14.285112249501509 |\n",
      "|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2017-12-30|21.6|5.3 |14.539211503699956 |\n",
      "|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2017-01-05|22.2|5.8 |14.748862551376547 |\n",
      "|CINCINNATI MUNICIPAL AIRPORT LUNKEN FIELD, OH US|2017-12-26|23.3|6.2 |15.688977064714743 |\n",
      "+------------------------------------------------+----------+----+----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "# Define the file path and load Cincinnati 2017 data\n",
    "cincinnati_2017_file = \"./weather_data/2017_72429793812.csv\"\n",
    "cincinnati_2017_df = spark.read.option(\"header\", \"true\").csv(cincinnati_2017_file)\n",
    "\n",
    "# Convert TEMP and WDSP to float, filter based on conditions, and calculate Wind Chill\n",
    "wind_chill_df = cincinnati_2017_df.withColumn(\"TEMP\", col(\"TEMP\").cast(\"float\")) \\\n",
    "    .withColumn(\"WDSP\", col(\"WDSP\").cast(\"float\")) \\\n",
    "    .filter((col(\"TEMP\") < 50) & (col(\"WDSP\") > 3)) \\\n",
    "    .withColumn(\"Wind_Chill\",\n",
    "        35.74 + (0.6215 * col(\"TEMP\")) - (35.75 * (col(\"WDSP\") ** 0.16)) + (0.4275 * col(\"TEMP\") * (col(\"WDSP\") ** 0.16))\n",
    "    )\n",
    "\n",
    "# Select and display the top 10 days with the lowest Wind Chill\n",
    "top_10_lowest_wc = wind_chill_df.orderBy(\"Wind_Chill\").select(\"NAME\", \"DATE\", \"TEMP\", \"WDSP\", \"Wind_Chill\").limit(10)\n",
    "\n",
    "print(\"\\nTop 10 Days with the Lowest Wind Chill for Cincinnati in 2017:\\n\")\n",
    "top_10_lowest_wc.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c69b733d-d8f3-4daa-9b2d-587597224786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days with extreme weather conditions in Florida across all years (excluding 2016): 0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Define file paths for Florida data across all years except 2016\n",
    "florida_files = [f\"./weather_data/{year}_99495199999.csv\" for year in years if year != 2016]\n",
    "\n",
    "# Load data for all available years for Florida\n",
    "florida_df = spark.read.option(\"header\", \"true\").csv(florida_files)\n",
    "\n",
    "# Filter for days with any extreme weather condition in the FRSHTT column\n",
    "extreme_weather_df = florida_df.filter(\n",
    "    (col(\"FRSHTT\").substr(1, 1) == \"1\") |  # Fog\n",
    "    (col(\"FRSHTT\").substr(2, 1) == \"1\") |  # Rain or Drizzle\n",
    "    (col(\"FRSHTT\").substr(3, 1) == \"1\") |  # Snow or Ice Pellets\n",
    "    (col(\"FRSHTT\").substr(4, 1) == \"1\") |  # Hail\n",
    "    (col(\"FRSHTT\").substr(5, 1) == \"1\") |  # Thunder\n",
    "    (col(\"FRSHTT\").substr(6, 1) == \"1\")    # Tornado or Funnel Cloud\n",
    ")\n",
    "\n",
    "# Count the number of days with extreme weather across all years (except 2016)\n",
    "extreme_weather_days_count = extreme_weather_df.count()\n",
    "\n",
    "# Display the result\n",
    "print(f\"Number of days with extreme weather conditions in Florida across all years (excluding 2016): {extreme_weather_days_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f8a59427-12d2-495d-9674-ee3bbea57e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- November Predictions ---\n",
      "\n",
      "Predicted Maximum Temperature for November 2024 (Average Method): 78.00°F\n",
      "\n",
      "Regression Model for November:\n",
      "Coefficients: [4.0090878636384]\n",
      "Intercept: 76.00\n",
      "R-squared: 0.9979\n",
      "RMSE: 0.0955\n",
      "Predicted Maximum Temperature for November 2024 (Regression Method): 84.01°F\n",
      "\n",
      "--- December Predictions ---\n",
      "\n",
      "Predicted Maximum Temperature for December 2024 (Average Method): 65.00°F\n",
      "\n",
      "Regression Model for December:\n",
      "Coefficients: [-1.8181818181818135]\n",
      "Intercept: 65.91\n",
      "R-squared: 0.9917\n",
      "RMSE: 0.0909\n",
      "Predicted Maximum Temperature for December 2024 (Regression Method): 62.27°F\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 10\n",
    "from pyspark.sql.functions import col, max as max_, year, month\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Define the years to use\n",
    "years = [2022, 2023]\n",
    "\n",
    "# Load data for Cincinnati from 2022 and 2023\n",
    "cincinnati_files = [f\"./weather_data/{y}_72429793812.csv\" for y in years]\n",
    "cincinnati_df = spark.read.option(\"header\", \"true\").csv(cincinnati_files)\n",
    "\n",
    "# Convert MAX to float and add YEAR and MONTH columns\n",
    "cincinnati_df = cincinnati_df.withColumn(\"MAX\", col(\"MAX\").cast(FloatType())) \\\n",
    "                             .withColumn(\"YEAR\", year(col(\"DATE\"))) \\\n",
    "                             .withColumn(\"MONTH\", month(col(\"DATE\")))\n",
    "\n",
    "# Filter to only valid MAX temperatures within a realistic range\n",
    "cincinnati_df = cincinnati_df.filter(col(\"MAX\").isNotNull()) \\\n",
    "                             .filter((col(\"MAX\") > -50) & (col(\"MAX\") < 150))\n",
    "\n",
    "# Function to get maximum temperature for a specific year and month\n",
    "def get_max_temp_for_month(df, year_value, month_value):\n",
    "    result = df.filter((col(\"YEAR\") == year_value) & (col(\"MONTH\") == month_value)) \\\n",
    "               .agg(max_(\"MAX\").alias(\"Max_Temp\")) \\\n",
    "               .collect()\n",
    "    return result[0][\"Max_Temp\"] if result else None\n",
    "\n",
    "# Prepare lists to store the data\n",
    "november_data = []\n",
    "december_data = []\n",
    "\n",
    "# Extract maximum temperatures for November and December from 2022 and 2023\n",
    "for y in years:\n",
    "    nov_max_temp = get_max_temp_for_month(cincinnati_df, y, 11)\n",
    "    dec_max_temp = get_max_temp_for_month(cincinnati_df, y, 12)\n",
    "    \n",
    "    if nov_max_temp is not None:\n",
    "        november_data.append((y, nov_max_temp))\n",
    "    if dec_max_temp is not None:\n",
    "        december_data.append((y, dec_max_temp))\n",
    "\n",
    "# Check if we have enough data\n",
    "if len(november_data) == 0:\n",
    "    print(\"No valid data available for November.\")\n",
    "if len(december_data) == 0:\n",
    "    print(\"No valid data available for December.\")\n",
    "\n",
    "# Convert data to DataFrames for modeling\n",
    "november_df = spark.createDataFrame(november_data, [\"YEAR\", \"Max_Temp\"])\n",
    "december_df = spark.createDataFrame(december_data, [\"YEAR\", \"Max_Temp\"])\n",
    "\n",
    "# Option 1: Simple Average Prediction\n",
    "def predict_by_average(df, month_name):\n",
    "    avg_max_temp = df.agg({\"Max_Temp\": \"avg\"}).collect()[0][0]\n",
    "    print(f\"\\nPredicted Maximum Temperature for {month_name} 2024 (Average Method): {avg_max_temp:.2f}°F\")\n",
    "    return avg_max_temp\n",
    "\n",
    "# Option 2: Linear Regression Prediction\n",
    "def predict_by_regression(df, month_name):\n",
    "    # Prepare the data\n",
    "    df = df.withColumn(\"YEAR_OFFSET\", col(\"YEAR\") - 2022)\n",
    "    assembler = VectorAssembler(inputCols=[\"YEAR_OFFSET\"], outputCol=\"features\")\n",
    "    df = assembler.transform(df)\n",
    "    \n",
    "    # Check if we have enough data points\n",
    "    if df.count() < 2:\n",
    "        print(f\"Not enough data to perform regression for {month_name}.\")\n",
    "        return None\n",
    "    \n",
    "    # Train the model\n",
    "    lr = LinearRegression(featuresCol=\"features\", labelCol=\"Max_Temp\", regParam=0.1)\n",
    "    lr_model = lr.fit(df)\n",
    "    \n",
    "    # Prepare test data for 2024\n",
    "    test_df = spark.createDataFrame([(2024 - 2022,)], [\"YEAR_OFFSET\"])\n",
    "    test_df = assembler.transform(test_df)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = lr_model.transform(test_df).collect()[0][\"prediction\"]\n",
    "    \n",
    "    # Print model coefficients and metrics\n",
    "    print(f\"\\nRegression Model for {month_name}:\")\n",
    "    print(f\"Coefficients: {lr_model.coefficients}\")\n",
    "    print(f\"Intercept: {lr_model.intercept:.2f}\")\n",
    "    training_summary = lr_model.summary\n",
    "    print(f\"R-squared: {training_summary.r2:.4f}\")\n",
    "    print(f\"RMSE: {training_summary.rootMeanSquaredError:.4f}\")\n",
    "    print(f\"Predicted Maximum Temperature for {month_name} 2024 (Regression Method): {prediction:.2f}°F\")\n",
    "    return prediction\n",
    "\n",
    "# Predictions for November\n",
    "if len(november_data) >= 2:\n",
    "    print(\"\\n--- November Predictions ---\")\n",
    "    nov_avg_pred = predict_by_average(november_df, \"November\")\n",
    "    nov_reg_pred = predict_by_regression(november_df, \"November\")\n",
    "elif len(november_data) == 1:\n",
    "    print(\"\\n--- November Predictions ---\")\n",
    "    nov_avg_pred = november_data[0][1]\n",
    "    print(f\"Only one data point available. Predicted Maximum Temperature for November 2024: {nov_avg_pred:.2f}°F\")\n",
    "else:\n",
    "    print(\"Insufficient data to make predictions for November 2024.\")\n",
    "\n",
    "# Predictions for December\n",
    "if len(december_data) >= 2:\n",
    "    print(\"\\n--- December Predictions ---\")\n",
    "    dec_avg_pred = predict_by_average(december_df, \"December\")\n",
    "    dec_reg_pred = predict_by_regression(december_df, \"December\")\n",
    "elif len(december_data) == 1:\n",
    "    print(\"\\n--- December Predictions ---\")\n",
    "    dec_avg_pred = december_data[0][1]\n",
    "    print(f\"Only one data point available. Predicted Maximum Temperature for December 2024: {dec_avg_pred:.2f}°F\")\n",
    "else:\n",
    "    print(\"Insufficient data to make predictions for December 2024.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1042aa5-1bc4-41c8-b941-15e1a60f2f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 Reasoning\n",
    "# By utilizing both simple averaging and linear regression on the recent two years of data (2022 and 2023), the model effectively predicts \n",
    "# the maximum temperatures for Cincinnati in November and December 2024. The averaging method provides a straightforward and reliable \n",
    "# estimate based on the most recent observations, while the linear regression introduces the potential to capture emerging trends, offering a\n",
    "# deeper analysis. This dual approach performs well given the data constraints, highlighting the model's adaptability and effectiveness. \n",
    "# To further enhance accuracy and reliability, incorporating additional historical data would allow for better trend identification and\n",
    "# reduce the risk of overfitting. Exploring advanced forecasting techniques like time-series models and including other relevant \n",
    "# variables such as climate indicators could also improve the model's predictive capabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
